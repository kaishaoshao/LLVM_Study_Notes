# MLIR Toy教程的全面解构：从高级语言到可执行代码

## 引言

在现代编译器基础设施领域，多层次中间表示（MLIR）项目代表了一次范式转变。它旨在解决在异构硬件（如CPU、GPU、TPU、FPGA）日益普及的背景下，不同计算领域（如机器学习、高性能计算）的软件栈碎片化问题。MLIR的核心思想是提供一个可扩展的、统一的基础设施，用于构建可复用的、模块化的编译器组件 ^^。**   **

为了引导开发者入门这一强大的框架，LLVM团队创建了Toy教程。该教程在MLIR生态系统中的地位，类似于LLVM自身的Kaleidoscope教程，是学习MLIR核心概念的经典“入门”范例 ^^。然而，Toy教程所展示的编译哲学更为现代和深刻。它不仅仅是关于如何构建一个编译器，更是关于如何实践“渐进式降低”（Progressive Lowering）这一核心理念 ^^。**   **

渐进式降低指的是将一个程序通过多个、语义逐渐降低的中间表示（IR）层次进行转换的过程。与传统的、从抽象语法树（AST）一步到位降低到低级IR（如LLVM IR）的“两阶段”编译模型不同，MLIR提倡在最合适的抽象层次上执行相应的分析和优化 ^^。例如，某些领域特定的优化（如张量操作的融合）在高层IR上更容易实现，而传统的循环优化则在更接近硬件的IR上效果更佳。**   **

本报告将对MLIR Toy教程的七个章节进行详尽的、专家级的剖析。我们将逐一解构从一个高级的、基于张量的Toy语言，到最终通过LLVM生成并在即时编译器（JIT）中执行的机器码的全过程。此行的目的不仅是解释每个阶段“做什么”，更是深入探讨其“为什么”如此设计，将教程中的具体实现与MLIR框架的底层设计哲学和工程考量紧密联系起来。

### **表1：MLIR Toy教程之旅：阶段与核心概念**

为了在深入细节之前提供一个全局视角，下表概括了Toy教程的整个编译流程。它清晰地展示了每个章节的目标、输入与输出的“制品”（Artifacts），以及引入的核心MLIR概念。这个表格可以作为一个高级路线图，帮助理解每个阶段在整个编译链条中的位置和作用。

| 阶段 (章节)      | 主要目标                                             | 关键制品 (输入 -> 输出)                               | 引入的核心MLIR概念                                                             |
| ---------------- | ---------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------------------ |
| **第一章** | 定义源语言并将其解析为结构化的内存表示。             | Toy源代码 -> 抽象语法树 (AST)                         | 语言设计, 词法/语法分析, AST结构                                               |
| **第二章** | 将前端AST转换为MLIR中的第一个高级IR。                | AST ->`toy`方言 MLIR                                | 方言 (Dialect), 操作 (Operation), ODS, TableGen, 属性 (Attribute), 类型 (Type) |
| **第三章** | 在高级IR上执行特定于语言的优化。                     | `toy`方言 -> 优化的 `toy`方言                     | 模式重写系统 (Pattern Rewriting), 规范化 (Canonicalization), 特性 (Traits)     |
| **第四章** | 编写可跨方言工作的通用转换。                         | `toy`方言 -> (通过接口) -> 优化的 `toy`方言       | 接口 (Interfaces), 方言无关的Pass                                              |
| **第五章** | 首次进行“降低”，将高级IR转换为标准的、更底层的IR。 | `toy`方言 ->`affine`,`arith`,`func`等标准方言 | 渐进式降低, 方言转换框架,`TensorType`vs `MemRefType`                       |
| **第六章** | 将IR降低到LLVM，并生成可执行代码。                   | 标准方言 ->`llvm`方言 -> LLVM IR                    | `llvm`方言, 与LLVM的集成, JIT编译                                            |
| **第七章** | 演示框架的可扩展性，为语言添加新特性。               | 扩展的Toy语言 -> 扩展的编译流程                       | 自定义类型 (Custom Types), 框架的可维护性与可扩展性                            |

Export to Sheets

---

## 第一部分：前端 - 定义和解析Toy语言 (第一章)

编译器的第一步始终是理解源代码。在Toy教程的第一章中，我们定义了一种专为教学目的而设计的简单语言，并构建了将其文本形式转换为结构化内存表示（即抽象语法树AST）的工具 ^^。**   **

### 1.1 Toy语言的剖析

Toy是一种基于张量的语言，其设计简洁，旨在突出编译器的核心挑战，而非语言本身的复杂性 ^^。**   **

* **基于张量的语义** : 语言的核心是张量计算。为了简化，它只支持64位浮点数（`f64`）类型和秩小于等于2的张量。所有值都是不可变的，这意味着每个操作都会返回一个新分配的值，内存管理是自动的 ^^。**   **
* **静态类型推断和泛型函数** : 这是Toy语言的一个关键特性。函数可以被泛型地定义，其参数类型是未指定秩的张量（例如，`tensor<*xf64>`）。编译器会在每个调用点根据传入参数的具体形状（shape）对函数进行“特化”（specialization）。如果后续有相同形状的调用，则会重用已特化的版本。这种设计直接反映了机器学习和DSL编译中的一个常见场景：需要根据编译时已知的元数据（如张量形状）来特化泛型代码 ^^。**   **
* **语法和内置函数** : Toy的语法非常直观。变量通过 `var`关键字定义，例如 `var a = [, ];`。函数通过 `def`关键字定义，如 `def multiply_transpose(a, b) {... }`。语言提供了两个内置函数：用于打印张量的 `print()`和用于转置的 `transpose()` ^^。**   **

### 1.2 词法分析器和语法分析器

为了处理Toy源代码，教程实现了一个标准的编译器前端。

* **词法分析器 (Lexer)** : `Lexer.h`中的词法分析器负责将源代码的字符流分解成一系列有意义的“令牌”（tokens），如关键字 `def`、标识符 `a`、数字 `1.0`等。
* **语法分析器 (Parser)** : `Parser.h`中的语法分析器是一个递归下降解析器。它接收词法分析器生成的令牌流，并根据语言的语法规则构建一个层次化的数据结构，即AST。

这两个组件的实现都相对直接，与LLVM Kaleidoscope教程中的类似，其主要目的是为后续的MLIR处理提供一个干净的、结构化的输入 ^^。**   **

### 1.3 抽象语法树 (AST)

AST是语法分析器的输出，也是程序在进入MLIR生态系统之前的最终表示。它是一个C++对象的树状层次结构，忠实地反映了程序的语法结构 ^^。例如，一个Toy程序会被解析成一个顶层的**   **

`ModuleAST`，其中包含一个或多个 `FunctionAST`。每个 `FunctionAST`又包含变量声明（`VarDeclExprAST`）、二元操作（`BinaryExprAST`）、函数调用（`CallExprAST`）等节点。通过 `-emit=ast`选项，我们可以看到Toy代码对应的AST文本表示，这使得从代码到其结构化表示的映射变得非常清晰 ^^。**   **

Toy语言的设计，特别是其泛型函数和形状推断机制，并非随意为之。它被精心设计出来，用以展示一个在机器学习和领域特定语言（DSL）编译器中普遍存在的核心问题：如何根据在编译时可知但在不同调用点之间变化的属性（如张量形状）来特化泛型代码。AST以一种高级形式捕获了这个问题。教程的其余部分，本质上就是展示如何使用MLIR来解决这个问题。因此，第一阶段的作用是为后续所有基于MLIR的转换和优化设置核心挑战。

---

## 第二部分：生成首个IR - The `Toy` 方言 (第二章)

在将AST转换为MLIR IR之前，必须先理解MLIR的基础结构。第二章的核心任务是定义一个专属于Toy语言的IR——`Toy`方言，并将第一章生成的AST“发射”（emit）为这种新的IR形式 ^^。**   **

### 2.1 MLIR基础概念

MLIR的IR结构由几个核心概念构成，它们共同组成了一个强大的、可扩展的系统 ^^。**   **

* **操作 (Operation)** : `Operation`是MLIR中执行和抽象的基本单元。可以说，“在MLIR中，一切皆为操作”。它可以代表任何东西，从高级的函数定义（`func.func`）到底层的算术加法（`arith.addf`）。
* **值 (Value)** : `Value`是一个 `Operation`的执行结果，或是一个 `Block`的参数。它们构成了静态单赋值（SSA）图的边，代表了数据流。可以将其类比为一个持有结果的变量。
* **属性 (Attribute)** : `Attribute`是附加在 `Operation`上的编译时常量元数据。例如，一个常数操作的数值、一个布尔标志等。它不是一个在运行时计算的 `Value`，而是一个固定的配置 ^^。**   **
* **类型 (Type)** : `Type`描述了一个 `Value`在编译时的信息，例如 `tensor<2x3xf64>`或 `i32`。
* **区域 (Region) 和 块 (Block)** : `Region`和 `Block`是构建层次化结构组件。一个 `Region`包含一个或多个 `Block`，一个 `Block`包含一个或多个 `Operation`。例如，一个函数的函数体就是一个 `Region`。

### 2.2 方言的力量

方言（Dialect）是MLIR可扩展性的核心机制 ^^。一个方言本质上是一个命名空间（例如**   **

`toy.`），它将一组自定义的 `Operation`、`Type`和 `Attribute`组合在一起。通过定义 `Toy`方言，我们能够创建一个高级的、领域特定的IR，它能完美地捕捉源语言的语义。

### 2.3 使用ODS和TableGen定义 `Toy`方言

这是本章的核心技术。MLIR推崇使用声明式的方法来定义IR组件，以避免编写大量重复的C++样板代码。

* **操作定义规范 (ODS)** : 我们不直接编写C++类来定义操作，而是使用一种名为TableGen的语言，在 `.td`文件中以声明式的方式描述我们的方言 ^^。**   **
* **TableGen 定义示例** : 以 `toy.constant`操作为例，其在 `ToyOps.td`中的定义可能如下所示 ^^：**   **

  **Code snippet**

```
  def ConstantOp : Toy_Op<"constant"> {
    let arguments = (ins F64ElementsAttr:$value);
    let results = (outs F64Tensor);
  }
```

  这里，`arguments`字段声明了该操作接受一个名为 `value`的、类型为 `F64ElementsAttr`的属性作为输入。`results`字段声明了该操作产生一个 `F64Tensor`类型的结果。

当构建项目时，MLIR的工具链会解析这些 `.td`文件，并自动生成相应的C++类、解析器/打印器逻辑、验证器等。这种“单一事实来源”（single source of truth）的设计哲学是MLIR工程实践的基石 ^^。它极大地降低了创建和维护新方言的成本，使得“可扩展IR”从一个学术概念变为了一个切实可行的工程实践。正是这种自动化，使得MLIR能够成功地支持从TensorFlow到CIRCT（硬件设计）等多样化的领域。**   **

一个最终生成的 `Toy`方言操作，在其文本形式中，包含了丰富的信息，每个部分都有明确的含义 ^^：**   **

* `%t_tensor`: 操作定义的结果的名称（SSA值）。
* `"toy.transpose"`: 操作的唯一名称，由方言名 `toy`和操作名 `transpose`组成。
* `(%tensor)`: 输入操作数列表，它们是其他操作定义的SSA值。
* `{ inplace = true }`: 属性字典，这里定义了一个名为 `inplace`的布尔属性。
* `(tensor<2x3xf64>) -> tensor<3x2xf64>`: 操作的函数类型，描述了输入和输出 `Value`的 `Type`。
* `loc("example/file/path":12:1)`: 源代码位置信息，用于调试。在MLIR中，位置信息是核心要求，而非像LLVM中可丢弃的元数据 ^^。**   **

### 2.4 代码生成：遍历AST以生成 `Toy`IR

最后一步是编写C++代码，遍历第一章生成的AST。对于每个AST节点，使用 `MLIRContext`和 `OpBuilder`等工具来创建相应的MLIR `Operation`。这是一个机械的转换过程，将程序的语言级表示（AST）转换成了MLIR的IR表示。

---

## 第三部分：高级优化 - 模式重写系统 (第三章)

如果说第二章是关于如何“表示”程序，那么第三章就是关于如何“改进”它。本章展示了拥有一个自定义高级方言的直接回报：能够轻松实现强大的领域特定优化 ^^。**   **

### 3.1 在正确的抽象层次上进行优化

本章的核心论点是：当你拥有一个与语言语义紧密匹配的IR时（即 `Toy`方言），执行特定于语言的优化会变得非常简单。

经典的例子是消除连续两次的转置操作：`transpose(transpose(x))`应该等价于 `x`。在 `Toy`方言的IR中，这个模式可以清晰地表示为两个连续的 `toy.transpose`操作：

**MLIR**

```
%0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
%1 = toy.transpose(%0 : tensor<*xf64>) to tensor<*xf64>
toy.return %1 : tensor<*xf64>
```

然而，如果将这段代码直接降低到像LLVM IR这样的低级表示，`transpose`的语义会丢失在一堆复杂的循环和内存访问指令中。对于编译器来说，要从这些低级指令中“恢复”出原始的转置语义并发现可以抵消的模式，将极其困难，甚至是不可能的 ^^。这清晰地表明，选择的IR抽象层次直接决定了哪些优化是可行的。**   **

`Toy`方言不仅仅是一种表示，它更是一系列强大分析和转换的“使能器”。

### 3.2 通用DAG重写器

MLIR提供了一套强大的模式匹配和重写基础设施，用于实现这类转换。

* **C++ `RewritePattern`** : 教程展示了如何通过C++实现一个重写模式。`SimplifyRedundantTranspose`类继承自 `OpRewritePattern<TransposeOp>`，它专门用于匹配 `toy.transpose`操作。其核心是 `matchAndRewrite`方法，该方法在IR中寻找 `transpose(transpose(x))`的模式，并使用 `rewriter`对象将匹配到的操作替换为原始输入 `x` ^^。**   **
* **规范化Pass** : 这些单独的重写模式被收集到一个 `RewritePatternSet`中，并由一个通用的Pass——规范化器（Canonicalizer）来应用。通过在Pass管理器中添加 `createCanonicalizerPass()`，我们就可以将自定义的优化逻辑集成到标准的MLIR优化流程中 ^^。**   **

### 3.3 特性（Traits）的角色

在将 `transpose(transpose(x))`替换为 `x`之后，原来的两个 `transpose`操作变成了无用代码（Dead Code）。然而，默认情况下，MLIR不会移除它们，因为它保守地假设任何操作都可能有副作用。

这时，`Traits`就派上了用场。`Traits`是附加到操作定义上的标签，用于向整个系统宣告该操作的某些通用属性。通过在 `TransposeOp`的TableGen定义中添加 `let traits = [Pure];`，我们向编译器保证这个操作是“纯”的，即没有副作用。有了这个保证，像规范化器这样的通用Pass就可以在确定其结果未被使用时，安全地将其消除 ^^。**   **

### 3.4 声明式重写规则 (DRR)

除了C++，MLIR还提供了声明式重写规则（Declarative Rewrite Rules, DRR），这是一种更简洁的、基于TableGen的声明式方式来定义重写模式，例如 `RedundantReshapeOptPattern` ^^。这再次强化了MLIR“声明式优先”的设计哲学。**   **

---

## 第四部分：通用抽象 - 使用接口编写方言无关的Pass (第四章)

第三章展示了如何为特定方言编写优化，而第四章则将抽象层次再提升一步，探讨如何编写能够跨越多个方言工作的通用转换逻辑 ^^。**   **

### 4.1 方言特定逻辑的局限性

第三章中的 `SimplifyRedundantTranspose`模式被硬编码为只对 `toy.transpose`操作有效。这是一个限制。如果我们想编写一个通用的内联器（Inliner）或形状推断引擎，我们不希望为每个方言都重写一遍逻辑。我们希望编写一次，就能在任何“行为类似”的方言上使用。

### 4.2 MLIR接口：通用代码的契约

`Interfaces`是MLIR针对这一挑战的解决方案。一个接口（Interface）定义了一份“契约”或一组方法。任何方言中的操作，只要声明自己实现了这个接口，并提供了接口所要求的方法的C++实现，就可以被那些针对该接口编写的通用代码所处理 。这类似于C++中的抽象基类或Java中的接口。

这种设计实现了关注点的分离：通用转换算法（如内联）与方言的具体语义（如何处理一个 `toy.func`或 `toy.call`）被解耦。这对于构建一个可扩展的编译器生态系统至关重要。我们不需要为N个方言编写N个内联器，而是编写一个通用的内联器，然后让N个方言各自实现内联接口。

### 4.3 案例研究1：形状推断

教程展示了一个通用的形状推断Pass。这个Pass可以遍历IR，对任何实现了 `ShapeInference`接口的操作进行形状推断。为了让 `Toy`方言加入这个体系，我们需要：

1. 在 `toy.transpose`和 `toy.mul`等操作的TableGen定义中，声明它们实现了 `ShapeInference`接口。
2. 在C++中，为这些操作提供接口所要求的 `shape_inference`方法的具体实现。该方法根据输入的形状计算输出的形状。

### 4.4 案例研究2：内联

同样，通用的内联Pass可以内联任何实现了 `FunctionOpInterface`的类函数操作（Function-like Operation）中的代码，到任何实现了 `CallOpInterface`的调用点。通过让 `toy.func`实现 `FunctionOpInterface`，让 `toy.call`实现 `CallOpInterface`，通用的内联器就可以在不知道任何关于“Toy”方言具体细节的情况下，对Toy代码进行内联。

教程的抽象层次是逐步递进的。第二章是关于*定义*方言。第三章是关于编写*方言特定*的转换。第四章则是关于编写*方言无关*的转换。这个递进关系是精心设计的，它展示了MLIR如何为具体和通用的问题都提供强大的工具。接口的存在，是对在多方言世界中实现代码复用这一挑战的直接回应。

---

## 第五部分：渐进式降低 - 从 `Toy`到标准方言 (第五章)

这是整个编译流程中的第一个主要的“降低”（Lowering）步骤。其目标是将我们自定义的、高级的 `Toy`方言，转换为一组标准的、定义良好的、更接近底层的MLIR方言，如 `Affine`、`Arith`和 `Func` ^^。这样做的目的是为了能够利用这些标准方言附带的、强大的、早已存在的优化Pass ^^。**   **

### 5.1 多层次哲学的实践

这一步是MLIR多层次理念的直接体现。我们不再停留在 `Toy`的抽象世界，而是开始向更具体的计算模型迈进。

### 5.2 方言转换框架

MLIR提供了一个专门的方言转换框架（Dialect Conversion Framework）来管理这种复杂的、跨方言的转换。其核心组件包括 ^^：**   **

* **`ConversionTarget`** : 它定义了转换完成后的IR应该处于什么样的“合法”（legal）状态。在本章中，我们将 `Affine`、`Arith`、`Func`和 `MemRef`方言标记为合法。这意味着转换结束后，IR中不应再有其他方言的操作（除了我们特意保留的）。
* **`RewritePatternSet`** : 一组重写模式的集合，这些模式定义了如何将“非法”的 `Toy`操作转换为“合法”的标准方言操作。
* **`TypeConverter`** : 一个类型转换器，用于将一种方言中的类型转换为另一种方言中的类型。

### 5.3 弥合语义鸿沟：`TensorType` 到 `MemRefType`

这是本章最关键、也最具挑战性的概念。`Toy`方言操作的是 `TensorType`，它具有 **值语义** （value semantics），就像C++中的 `int`一样，代表一个抽象的数学对象。而 `Affine`方言操作的是 `MemRefType`（Memory Reference Type），它具有 **缓冲区/内存语义** （buffer/memory semantics），更像C++中的 `int*`，它代表对一块内存的引用，并意味着显式的内存分配和访问 ^^。**   **

这个从值语义到引用语义的转换，是从计算的“是什么”（what）到“如何在内存中实现”（how）的转变。教程中 `toy.transpose`的降低过程完美地展示了这一点：

1. 转换模式 `TransposeOpLowering`接收一个 `memref`作为输入。
2. 它使用 `memref.alloc`操作为输出分配一块新的内存（一个新的 `memref`）。
3. 然后，它生成一个 `affine.for`循环嵌套，从输入 `memref`中加载（`affine.load`）元素，进行转置计算，并将结果存储（`affine.store`）到输出 `memref`中。
4. 最后，在函数末尾，需要插入 `memref.dealloc`来释放分配的内存。

通过这个降低过程，原本抽象的 `toy.transpose`操作被具体化为一系列显式的内存操作和循环。

### 5.4 解锁标准优化

降低完成后，IR中不再有 `toy.transpose`和 `toy.mul`等操作，取而代之的是 `affine.for`循环。现在，我们可以应用MLIR中强大的标准优化Pass，如循环融合（`--affine-loop-fusion`）和仿射标量替换（`--affine-scalar-replacement`）。这些Pass可以分析 `affine`循环，合并循环嵌套，消除冗余的内存分配和访问，从而生成高效得多的代码。这些优化在原始的、抽象的 `Toy` IR上是无法应用的 ^^。**   **

值得注意的是，这次降低是“部分”的（Partial Lowering），因为 `toy.print`操作被保留了下来。这是因为将张量代数降低为仿射循环，和将I/O操作降低为外部库调用（如 `printf`）是两个不同关注点的问题。MLIR的设计鼓励这种分阶段的降低，使每一步都更简单、更模块化。为了让 `toy.print`能继续工作，教程选择更新其定义，使其既能接受 `TensorType`也能接受 `MemRefType`，这是一个在弥合抽象鸿沟时常见的务实工程决策 ^^。**   **

---

## 第六部分：最终阶段 - 降低到LLVM和JIT执行 (第六章)

这是编译流程的最后一英里，目标是将MLIR IR完全转换为可以在目标硬件上执行的代码。这一阶段的核心是 `LLVM`方言和LLVM项目本身 ^^。**   **

### 6.1 `LLVM`方言：通往LLVM生态系统的桥梁

`LLVM`方言是MLIR中一个特殊的方言。它的关键特性是其操作和类型与LLVM IR本身有几乎一对一的映射关系 ^^。这个方言扮演了从MLIR世界到LLVM世界的“出口匝道”的角色。通过降低到**   **

`LLVM`方言，任何基于MLIR构建的编译器都可以立即利用整个LLVM基础设施——一个经过数十年发展、经过实战检验的、世界级的后端，用于针对各种CPU和其他目标进行最终的代码优化和生成。这体现了MLIR一个至关重要的设计原则：复用，而不是重新发明轮子。

### 6.2 最终转换

我们再次使用方言转换框架，但这次的 `ConversionTarget`被设置为 `LLVM`方言 (`target.addLegalDialect<mlir::LLVMDialect>()`) ^^。所有剩下的**   **

`Affine`、`Arith`、`Func`方言的操作，以及最后一个 `Toy`方言的操作 `toy.print`，都会被转换为 `LLVM`方言中的等价物。

例如，`affine.for`循环会被降低为LLVM IR中标准的基于分支和比较的循环结构。而 `toy.print`操作则会被降低为一个对外部C函数 `printf`的调用，这展示了如何与外部库代码进行交互。

### 6.3 生成LLVM IR

当整个模块都只由 `LLVM`方言的操作构成时，MLIR的使命就基本完成了。我们只需调用一个工具函数 `mlir::translateModuleToLLVMIR`，就可以将MLIR的内存表示转换为一个标准的 `llvm::Module`对象，即LLVM的原生IR表示 ^^。**   **

为什么不直接从MLIR生成LLVM IR文本，而要通过一个专门的 `LLVM`方言呢？因为这使得向LLVM的转换可以被与所有其他降低过程相同的、健壮的、类型安全的、可验证的机制（即方言转换框架）来管理。这保证了整个编译管线从上到下都是一致和有原则的，而不是在最后一步有一个特殊处理的“后门”。

### 6.4 JIT执行

为了验证我们编译器的正确性并看到最终结果，教程使用了 `mlir::ExecutionEngine` ^^。这是一个围绕LLVM JIT功能的实用工具封装。它接收**   **

`llvm::Module`，在内存中即时地将其编译成机器码，并提供一个钩子，允许我们按名称查找并调用其中的函数（例如 `invoke("main")`）。这提供了一个端到端的、可执行的验证流程，而无需将目标文件写入磁盘再链接执行。

---

## 第七部分：演示可扩展性 - 添加复合类型 (第七章)

这一章可以看作是一个毕业设计项目。它旨在证明我们在前六章中构建的编译器架构是可扩展和可维护的，能够轻松地添加新的语言特性 ^^。**   **

### 7.1 MLIR的灵活性

本章通过为Toy语言添加一个 `struct`（结构体）复合类型来展示MLIR的灵活性。

### 7.2 定义自定义 `Struct`类型

与第二章定义操作类似，我们可以在TableGen中声明一个新的 `toy.struct`类型，定义其内部存储结构和文本表示格式。

### 7.3 集成新类型

添加一个新特性需要对整个编译管线进行更新，但由于MLIR的模块化设计，这个过程是结构化的，而非侵入式的：

* **前端** : 更新词法和语法分析器以识别 `struct`的字面量和语法。
* **`Toy`方言** : 添加新的操作来创建 `struct`实例和访问其成员。
* **降低过程** : 更新从 `Toy`到标准方言以及从标准方言到 `LLVM`方言的降低Pass，使其能够处理新的 `struct`操作和类型，将它们转换为下层IR中的等价结构（例如，LLVM IR中的 `struct`类型）。

本章的意义在于证明了之前所有努力的价值。因为编译器的每个阶段都定义良好，且它们之间的接口（方言、接口、转换框架）是清晰的，所以添加一个新特性不再是一项艰巨的任务。它变成了一个在每个阶段“插入”新逻辑的局部化过程。这展示了MLIR方法在构建复杂、不断演进的编译器时所具有的卓越的可维护性和可扩展性。教程本可以在第六章结束，但第七章的存在回答了任何真实编译器项目都会面临的关键问题：“以后修改或添加功能有多难？”通过展示添加一个像复合类型这样的基础特性是一个结构化且可管理的过程，教程证明了MLIR框架不仅适用于玩具示例，更是构建生产级系统的坚实基础。
